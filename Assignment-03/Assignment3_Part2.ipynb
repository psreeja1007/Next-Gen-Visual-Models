{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XMLcIMAIHF6l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16, VGG19, InceptionV3\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR10 data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize\n",
        "y_train, y_test = to_categorical(y_train, 10), to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "GwhXK7QFHLqV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754c4424-87c3-4457-881f-1e980033547f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a pre-trained model (e.g., VGG19)\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gt_nbU9FHOw2",
        "outputId": "c343c2e6-83e6-40ca-b186-2e1c754ac589"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add custom top layers for CIFAR10\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512),\n",
        "    layers.LeakyReLU(alpha=0.1),  # Leaky ReLU activation\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(256),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128),\n",
        "    layers.LeakyReLU(alpha=0.1),\n",
        "    layers.Dense(10, activation='softmax')  # Output for CIFAR10\n",
        "])\n",
        "\n",
        "# Freeze base model layers for initial evaluation\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "Y8krb-8BHSOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84d3edb-80fa-4da1-eee3-9f00d1da2a87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and evaluate without fine-tuning\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Evaluating with pre-trained weights:\")\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sk7J4FLEHW7a",
        "outputId": "a4e60618-2cf2-4b52-db22-174b3f698c32"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating with pre-trained weights:\n",
            "313/313 - 7s - 23ms/step - accuracy: 0.1069 - loss: 2.3331\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.333101272583008, 0.10689999908208847]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = True  # Unfreeze for fine-tuning\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pEMwuqtoHZn7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykAV6diFHk5C",
        "outputId": "3f69574e-57c4-40d2-f7a4-532ec7aabc71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 50ms/step - accuracy: 0.3255 - loss: 1.8550 - val_accuracy: 0.6974 - val_loss: 0.8933\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 46ms/step - accuracy: 0.6920 - loss: 0.9477 - val_accuracy: 0.7490 - val_loss: 0.7537\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.7631 - loss: 0.7400 - val_accuracy: 0.7892 - val_loss: 0.6448\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.8041 - loss: 0.6121 - val_accuracy: 0.7916 - val_loss: 0.6434\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 47ms/step - accuracy: 0.8360 - loss: 0.5237 - val_accuracy: 0.8218 - val_loss: 0.5388\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 46ms/step - accuracy: 0.8613 - loss: 0.4386 - val_accuracy: 0.8259 - val_loss: 0.5341\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 47ms/step - accuracy: 0.8784 - loss: 0.3809 - val_accuracy: 0.8283 - val_loss: 0.5545\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 46ms/step - accuracy: 0.8935 - loss: 0.3331 - val_accuracy: 0.8312 - val_loss: 0.5480\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 47ms/step - accuracy: 0.9139 - loss: 0.2746 - val_accuracy: 0.8307 - val_loss: 0.6182\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 46ms/step - accuracy: 0.9270 - loss: 0.2301 - val_accuracy: 0.8380 - val_loss: 0.5609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model\n",
        "print(\"Evaluating after fine-tuning:\")\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJNAyOUxHmmR",
        "outputId": "e30d8112-5892-4ae6-e941-9857be2006f1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating after fine-tuning:\n",
            "313/313 - 3s - 8ms/step - accuracy: 0.8380 - loss: 0.5609\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5608878135681152, 0.8379999995231628]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eB4WD9HYKjtM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}